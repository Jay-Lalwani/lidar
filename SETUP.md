# PointPillars LiDAR Detection — Complete Setup Guide

End-to-end instructions for training a PointPillars model on IAC racecar
LiDAR data using OpenPCDet on the UVA HPC cluster.

---

## Directory Structure

```
/p/cavalier/jay/
├── SETUP.md                  ← this file
├── .gitignore
├── scripts/
│   ├── preprocess_kitti.py   ← raw data → KITTI format
│   ├── setup_env.sh          ← one-time env + build
│   └── train_pointpillars.slurm  ← SLURM training job
├── OpenPCDet/                ← cloned from github.com/open-mmlab/OpenPCDet
│   ├── tools/cfgs/
│   │   ├── dataset_configs/kitti_dataset.yaml   (customised)
│   │   └── kitti_models/pointpillar.yaml        (customised)
│   ├── data/kitti/           ← preprocessed dataset
│   │   ├── training/{velodyne,label_2,calib,image_2}/
│   │   ├── testing -> training   (symlink)
│   │   ├── ImageSets/{train,val,test}.txt
│   │   ├── gt_database/          (generated by step 5)
│   │   └── kitti_infos_*.pkl     (generated by step 5)
│   └── output/               ← training checkpoints + logs
└── envs/openpcdet/           ← conda environment (not in git)
```

---

## Step 0 — Clone OpenPCDet (if starting fresh)

```bash
cd /p/cavalier/jay
git clone https://github.com/open-mmlab/OpenPCDet.git
```

Then apply the required patch and copy in configs:



**Patch `torch.load` for PyTorch 2.6+** (default changed to `weights_only=True`,
which rejects checkpoints saved with older PyTorch):

Edit `OpenPCDet/pcdet/models/detectors/detector3d_template.py` and add
`weights_only=False` to all `torch.load()` calls (4 occurrences).

**Copy in the two custom config files:**

| File | Location inside OpenPCDet |
|------|--------------------------|
| `kitti_dataset.yaml` | `tools/cfgs/dataset_configs/kitti_dataset.yaml` |
| `pointpillar.yaml` | `tools/cfgs/kitti_models/pointpillar.yaml` |

These configs are tuned for our racecar dataset:

- **Point cloud range**: `[-20.48, -39.68, -3, 199.68, 39.68, 1]`
  (covers behind-car and 200 m forward, ±40 m lateral)
- **FOV_POINTS_ONLY**: `False` (we use full 360° LiDAR)
- **USE_ROAD_PLANE**: `False` (no road plane files)
- **Single class**: `Car` only
- **Anchor size**: `[5.0, 2.0, 1.5]` matching IAC racecar dimensions
- **Voxel size**: `[0.16, 0.16, 4]` (standard PointPillars pillars)

---

## Step 1 — Set Up the Conda Environment

Submit the one-time setup script on a GPU node:

```bash
mkdir -p /p/cavalier/jay/logs
sbatch -p gpu --gres=gpu:a100:1 -c 4 --mem=32G -t 01:00:00 \
       -o /p/cavalier/jay/logs/setup-%A.out \
       -e /p/cavalier/jay/logs/setup-%A.err \
       scripts/setup_env.sh
```

**What it does:**
1. Loads `miniforge/25.3.1-py3.12` and `cuda/12.8.1` modules
2. Creates a conda env at `/p/cavalier/jay/envs/openpcdet` (Python 3.10)
3. Installs PyTorch with CUDA 12.8 via pip
4. Installs `spconv-cu124` (provides voxelisation for PointPillars)
5. Installs remaining deps (numpy, scipy, tqdm, tensorboardX, etc.)
6. Builds OpenPCDet CUDA extensions (`pip install -e . --no-build-isolation`)
7. Verifies the full stack (PyTorch, pcdet, iou3d_nms_cuda, spconv)

**Check the output:**

```bash
cat /p/cavalier/jay/logs/setup-<JOBID>.out
```

You should see:

```
PyTorch:        2.x.x+cu128
CUDA available: True
OpenPCDet:      OK
iou3d_nms_cuda: OK
spconv voxel:   OK
```

> **Note**: If you only need to rebuild CUDA extensions after a fresh clone
> (env already exists), just run:
> ```bash
> module load miniforge/25.3.1-py3.12 cuda/12.8.1
> conda activate /p/cavalier/jay/envs/openpcdet
> cd /p/cavalier/jay/OpenPCDet && pip install -e . --no-build-isolation
> ```

---

## Step 2 — Preprocess Raw Data

Convert the raw LiDAR export into KITTI format:

```bash
module load miniforge/25.3.1-py3.12
conda activate /p/cavalier/jay/envs/openpcdet

python scripts/preprocess_kitti.py \
    --input  /p/cavalier/data/processed/2025_01_06_PolimoveUnimore_KITTI \
    --output /p/cavalier/jay/OpenPCDet/data/kitti
```

**What it does:**
1. Copies `.bin` point clouds with sequential 6-digit names (`000000.bin`, ...)
2. Transforms labels:
   - Renames all classes → `Car`
   - Adjusts Z coordinate: `z_new = z - H/2` (center → bottom-center)
   - Converts yaw → KITTI `rotation_y`: `ry = -yaw - π/2`
   - Replaces 2D bounding boxes with dummy values (ensures difficulty=Easy)
3. Copies calibration files as-is (identity transforms)
4. Creates dummy 100×100 black PNG images (OpenPCDet requires `image_2/`)
5. Creates `ImageSets/` with **only non-empty-label frames** (80/20 split)
6. Creates `testing -> training` symlink

**Expected output (~41 K frames, ~17 K with labels):**

```
ImageSets/train.txt -> ~13564 samples
ImageSets/val.txt   -> ~3390 samples
ImageSets/test.txt  -> ~3390 samples (same as val)
```

> **Dry run first?** Add `--dry_run` to preview without writing files.

---

## Step 3 — Generate Data Infos + GT Database

This step creates the `.pkl` info files and `gt_database/` that OpenPCDet
needs for training.  It runs automatically on the first training job, but
you can also run it manually:

```bash
cd /p/cavalier/jay/OpenPCDet
python -m pcdet.datasets.kitti.kitti_dataset create_kitti_infos \
    tools/cfgs/dataset_configs/kitti_dataset.yaml
```

This produces:
- `kitti_infos_train.pkl`, `kitti_infos_val.pkl`, `kitti_infos_trainval.pkl`, `kitti_infos_test.pkl`
- `kitti_dbinfos_train.pkl`
- `gt_database/` directory with individual object point clouds

---

## Step 4 — Train

Submit the training job:

```bash
sbatch scripts/train_pointpillars.slurm
```

**Configuration:**
- GPU: NVIDIA A100 (80 GB)
- Batch size: 16
- Epochs: 80
- Workers: 6
- Time limit: 12 hours

**To resume from a checkpoint** (e.g., after job timeout or to continue):

```bash
sbatch --export=RESUME=1 scripts/train_pointpillars.slurm
```

**Monitor training:**

```bash
# Job status
squeue -u $USER

# Training loss / metrics (updates every epoch)
tail -f /p/cavalier/jay/logs/pp_train-<JOBID>.out

# Check for errors
cat /p/cavalier/jay/logs/pp_train-<JOBID>.err
```

**Checkpoints** are saved to:
```
OpenPCDet/output/kitti_models/pointpillar/default/ckpt/
```

---

## Step 5 — Evaluate

After training, run evaluation on the validation set:

```bash
cd /p/cavalier/jay/OpenPCDet/tools
python test.py \
    --cfg_file cfgs/kitti_models/pointpillar.yaml \
    --batch_size 16 \
    --ckpt ../output/kitti_models/pointpillar/default/ckpt/checkpoint_epoch_80.pth
```

---

## Quick Reference

| Task | Command |
|------|---------|
| Activate env | `module load miniforge/25.3.1-py3.12 cuda/12.8.1 && conda activate /p/cavalier/jay/envs/openpcdet` |
| Build OpenPCDet | `cd /p/cavalier/jay/OpenPCDet && pip install -e . --no-build-isolation` |
| Preprocess data | `python scripts/preprocess_kitti.py --input <RAW_DIR> --output OpenPCDet/data/kitti` |
| Train (new) | `sbatch scripts/train_pointpillars.slurm` |
| Train (resume) | `sbatch --export=RESUME=1 scripts/train_pointpillars.slurm` |
| Check job | `squeue -u $USER` |
| View logs | `tail -f /p/cavalier/jay/logs/pp_train-<JOBID>.out` |

---

## Config Changes from Stock OpenPCDet

### `kitti_dataset.yaml`
- `POINT_CLOUD_RANGE`: Extended to `[-20.48, -39.68, -3, 199.68, 39.68, 1]`
- `FOV_POINTS_ONLY`: `False`
- `USE_ROAD_PLANE`: `False`
- `filter_by_min_points`: `['Car:5']`
- `filter_by_difficulty`: `[]` (no difficulty filtering)
- `SAMPLE_GROUPS`: `['Car:15']`

### `pointpillar.yaml`
- `CLASS_NAMES`: `['Car']` (single class)
- `POINT_CLOUD_RANGE`: Matches dataset config
- `VOXEL_SIZE`: `[0.16, 0.16, 4]`
- `MAX_NUMBER_OF_VOXELS`: `train: 40000`, `test: 60000`
- `ANCHOR_GENERATOR_CONFIG`: Single `Car` anchor — `[5.0, 2.0, 1.5]`, `bottom_height: -0.75`

---

## Troubleshooting

| Symptom | Cause | Fix |
|---------|-------|-----|
| `ModuleNotFoundError: spconv` | spconv not installed | `pip install spconv-cu124` |
| `CUDA_HOME not set` | Module not loaded | `module load cuda/12.8.1` |
| `ValueError: need at least one array to concatenate` | Empty label files in ImageSets | Re-run `preprocess_kitti.py` (filters automatically) |
| `assert img_file.exists()` during infos | Missing `testing/` dir | `ln -sfn training testing` in `data/kitti/` |
| `Floating point exception` in cumm | spconv/cumm CUDA version mismatch | Use `spconv-cu124` (not cu120) |
| `FileNotFoundError: kitti_dataset.yaml` | Wrong CWD for train.py | Must `cd tools/` before running `train.py` |
| `Permission denied` (conda) | System cache read-only | Set `CONDA_PKGS_DIRS` to writable dir |
| `ModuleNotFoundError: av2` | Argo2 library missing | `pip install av2` (should be in setup script) |
| `UnpicklingError: Weights only load failed` | PyTorch 2.6+ `weights_only` default | Add `weights_only=False` to `torch.load()` in `detector3d_template.py` |
